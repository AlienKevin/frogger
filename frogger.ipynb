{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import ale_py  # Ensure Atari environments work\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import numpy as np\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "import collections\n",
    "import random\n",
    "from gymnasium.wrappers import GrayscaleObservation, ResizeObservation\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.10.2+c9d4b19)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"ALE/Frogger-v5\", render_mode=\"rgb_array\", frameskip=4, repeat_action_probability=0, mode=0)\n",
    "\n",
    "state, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 160, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lives': 4, 'episode_frame_number': 0, 'frame_number': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5668a4d0f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google import genai\n",
    "# client = genai.Client(api_key=os.environ.get(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from anthropic import Anthropic\n",
    "\n",
    "# client = Anthropic(api_key=os.environ.get(\"CLAUDE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def save_state(state, step):   \n",
    "    im = Image.fromarray(state)\n",
    "    os.makedirs('states', exist_ok=True)\n",
    "    im.save(f\"states/{step}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gemini(prompt, step, actions):\n",
    "    contents = []\n",
    "    for s in range(step-2, step+1):\n",
    "        contents.append(f'Step {s}: action {index_to_action(actions[s][0])} reward {actions[s][1]}')\n",
    "        contents.append(Image.open(f'states/{s}.png'))\n",
    "    contents.append(prompt)\n",
    "    \n",
    "    print(contents)\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=contents,\n",
    "        config = {\n",
    "            'response_mime_type': 'application/json',\n",
    "            'response_schema': { \"type\": \"OBJECT\",\n",
    "                \"properties\": {\n",
    "                    \"reasoning\": { \"type\": \"STRING\", \"description\": \"Step by step reasoning on which action to perform\" },\n",
    "                    \"action\": { \"type\": \"STRING\", \"enum\": [\"NOOP\", \"UP\", \"RIGHT\", \"LEFT\", \"DOWN\"], \"description\": \"Next action to perform\" }\n",
    "                },\n",
    "                \"required\": [\"reasoning\", \"action\"],\n",
    "                \"propertyOrdering\": [\"reasoning\", \"action\"]\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    response = json.loads(response.text)\n",
    "    print(response['reasoning'])\n",
    "    return response['action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "def image_to_base64(path):\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        binary_data = image_file.read()\n",
    "        base_64_encoded_data = base64.b64encode(binary_data)\n",
    "        base64_string = base_64_encoded_data.decode('utf-8')\n",
    "        return base64_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_claude(prompt, step, actions):\n",
    "    MODEL_NAME = \"claude-3-7-sonnet-20250219\"\n",
    "    content = []\n",
    "    for s in range(step-2, step+1):\n",
    "        content.append({\"type\": \"text\", \"text\": f'Step {s}: <action>{index_to_action(actions[s][0])}</action> reward {actions[s][1]}'})\n",
    "        content.append({\"type\": \"image\", \"source\": {\"type\": \"base64\", \"media_type\": \"image/png\", \"data\": image_to_base64(f'states/{s}.png')}})\n",
    "    content.append({\"type\": \"text\", \"text\": prompt})\n",
    "\n",
    "    message_list = [\n",
    "        {\n",
    "            \"role\": 'user',\n",
    "            \"content\": content\n",
    "        }\n",
    "    ]\n",
    "    print(message_list)\n",
    "\n",
    "    response = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=500,\n",
    "        messages=message_list\n",
    "    )\n",
    "\n",
    "    res = response.content[0].text\n",
    "    print(res)\n",
    "    match = re.search(\"<action>(.+)</action>\", res)\n",
    "    if match:\n",
    "        return match[1]\n",
    "    else:\n",
    "        return \"NOOP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_openai(prompt, step, actions):\n",
    "    content = []\n",
    "    for s in range(step-2, step+1):\n",
    "        content.append({\"type\": \"text\", \"text\": f'Step {s}: <action>{index_to_action(actions[s][0])}</action> reward {actions[s][1]}'})\n",
    "        content.append({\"type\": \"image_url\", \"image_url\": {\"url\": f'data:image/png;base64,{image_to_base64(f\"states/{s}.png\")}'}})\n",
    "    content.append({\"type\": \"text\", \"text\": prompt})\n",
    "\n",
    "    message_list = [\n",
    "        {\n",
    "            \"role\": 'user',\n",
    "            \"content\": content\n",
    "        }\n",
    "    ]\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"qwen2.5-vl-72b-instruct\",\n",
    "        messages=message_list\n",
    "    )\n",
    "\n",
    "    res = completion.choices[0].message.content\n",
    "    print(res)\n",
    "    match = re.search(\"<action>(.+)</action>\", res)\n",
    "    if match:\n",
    "        return match[1]\n",
    "    else:\n",
    "        return \"NOOP\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine the appropriate action, let's analyze the current state of the game and the potential outcomes of each action:\n",
      "\n",
      "1. **Current State Analysis**:\n",
      "   - The player is at the bottom of the screen.\n",
      "   - There are obstacles (green blocks) above the player.\n",
      "   - There are enemies (pink creatures) moving around.\n",
      "   - The player needs to navigate through the obstacles and avoid the enemies.\n",
      "\n",
      "2. **Action Evaluation**:\n",
      "   - **NOOP**: Doing nothing will not change the player's position. This might be useful if the player is in a safe spot and waiting for an opportunity to move.\n",
      "   - **UP**: Moving up will bring the player closer to the obstacles. This could be risky if the player is not aligned with a gap in the obstacles.\n",
      "   - **RIGHT**: Moving right will bring the player closer to the right side of the screen. This could be useful if there is a path on the right side.\n",
      "   - **LEFT**: Moving left will bring the player closer to the left side of the screen. This could be useful if there is a path on the left side.\n",
      "   - **DOWN**: Moving down will bring the player closer to the bottom of the screen. This might not be useful as the player is already at the bottom.\n",
      "\n",
      "3. **Decision Making**:\n",
      "   - From the current frame, it appears that moving right or left might be beneficial as there seem to be paths on both sides.\n",
      "   - Moving up might be risky as the player is not aligned with a clear gap in the obstacles.\n",
      "   - Moving down is not necessary as the player is already at the bottom.\n",
      "\n",
      "Given the analysis, the best action would be to move either right or left. Since the player is currently centered, moving right might be a good choice to explore the right side of the screen.\n",
      "\n",
      "<action>RIGHT</action>\n",
      "Step 108 action: 2\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. **Current State Analysis**:\n",
      "   - The player is at the bottom of the screen.\n",
      "   - There are obstacles (pink and purple shapes) in the middle of the screen.\n",
      "   - The player needs to navigate through these obstacles to reach the top.\n",
      "\n",
      "2. **Previous Actions**:\n",
      "   - Step 107: NOOP (no action) with a reward of 0.\n",
      "   - Step 108: NOOP (no action) with a reward of 0.\n",
      "   - Step 109: RIGHT with a reward of 0.0.\n",
      "\n",
      "3. **Reasoning**:\n",
      "   - The player has been moving right, but there are still obstacles ahead.\n",
      "   - To progress, the player needs to move up to avoid the obstacles and reach the top.\n",
      "\n",
      "4. **Action Selection**:\n",
      "   - Given the need to move up to avoid obstacles and progress, the best action is to move UP.\n",
      "\n",
      "Therefore, the action to take is <action>UP</action>.\n",
      "Step 109 action: 1\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions taken:\n",
      "\n",
      "1. **Step 108**: The action was `NOOP`, which resulted in no reward.\n",
      "2. **Step 109**: The action was `RIGHT`, which also resulted in no reward.\n",
      "3. **Step 110**: The action was `UP`, which resulted in a reward of 1.0.\n",
      "\n",
      "From the images:\n",
      "- In Step 108, the player is positioned at the bottom left corner.\n",
      "- In Step 109, the player moves to the right but does not encounter any rewards.\n",
      "- In Step 110, the player moves up and receives a reward, indicating that moving up is beneficial.\n",
      "\n",
      "Given this information, it seems that moving up is a successful strategy as it leads to a reward. Therefore, the next logical action would be to continue moving up.\n",
      "\n",
      "<action>UP</action>\n",
      "Step 110 action: 1\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions taken:\n",
      "\n",
      "1. **Step 109**: The action was `RIGHT`, and the reward was `0.0`. This suggests that moving right did not result in a positive outcome.\n",
      "2. **Step 110**: The action was `UP`, and the reward was `1.0`. Moving up resulted in a positive outcome.\n",
      "3. **Step 111**: The action was `UP` again, and the reward was `1.0`. Moving up again resulted in another positive outcome.\n",
      "\n",
      "From these observations:\n",
      "- Moving up has been successful in the last two steps, resulting in rewards.\n",
      "- There is no indication that moving in any other direction (NOOP, RIGHT, LEFT, DOWN) would be more beneficial based on the immediate past actions and rewards.\n",
      "\n",
      "Given this reasoning, the best action to take next is likely to continue moving up, as it has been yielding positive rewards.\n",
      "\n",
      "<action>UP</action>\n",
      "Step 111 action: 1\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions taken:\n",
      "\n",
      "1. **Previous Actions and Rewards**: The last three actions were all \"UP,\" and each resulted in a reward of 1.0. This suggests that moving up is beneficial in the current context.\n",
      "\n",
      "2. **Current Game State**:\n",
      "   - The player character appears to be at the bottom of the screen.\n",
      "   - There are platforms above the player that can be reached by moving up.\n",
      "   - No immediate obstacles or enemies are directly in the path of moving up.\n",
      "\n",
      "3. **Objective**: The goal seems to be reaching higher platforms or collecting items (possibly represented by the orange dots).\n",
      "\n",
      "4. **Action Analysis**:\n",
      "   - **NOOP**: Doing nothing would not help in progressing towards the goal.\n",
      "   - **UP**: Continuing to move up aligns with the previous successful actions and the apparent objective.\n",
      "   - **RIGHT** and **LEFT**: Moving horizontally does not seem necessary at this moment as there are no immediate horizontal objectives or threats.\n",
      "   - **DOWN**: Moving down would likely result in a loss of progress.\n",
      "\n",
      "Given the analysis, the most logical action is to continue moving up.\n",
      "\n",
      "<action>UP</action>\n",
      "Step 112 action: 1\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions taken:\n",
      "\n",
      "1. **Previous Actions and Rewards**: The last three steps involved moving UP, each resulting in a reward of 1.0. This suggests that moving UP is beneficial in the current context.\n",
      "\n",
      "2. **Current Game State**:\n",
      "   - The player character appears to be at the bottom of the screen.\n",
      "   - There are obstacles and possibly enemies above the player.\n",
      "   - The score has increased from 2 to 4, indicating successful progression.\n",
      "\n",
      "3. **Objective**: The goal seems to be navigating through the environment while avoiding obstacles and possibly collecting items or reaching higher levels.\n",
      "\n",
      "4. **Possible Actions**:\n",
      "   - **NOOP**: Doing nothing might not help progress.\n",
      "   - **UP**: Continuing to move up could help avoid obstacles and reach higher areas.\n",
      "   - **RIGHT** or **LEFT**: Moving horizontally might not be necessary if the objective is to navigate vertically.\n",
      "   - **DOWN**: Moving down would likely lead to collision with obstacles.\n",
      "\n",
      "Given the consistent rewards for moving UP and the need to navigate vertically, the best action is likely to continue moving UP.\n",
      "\n",
      "<action>UP</action>\n",
      "Step 113 action: 1\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions taken:\n",
      "\n",
      "1. **Previous Actions and Rewards**: The last three steps involved moving UP, each resulting in a reward of 1.0. This suggests that moving UP is beneficial in the current context.\n",
      "\n",
      "2. **Current Game State**:\n",
      "   - The player character (purple) is positioned near the center of the screen.\n",
      "   - There are obstacles and enemies above the player.\n",
      "   - The score has increased from 3 to 5, indicating successful progression.\n",
      "\n",
      "3. **Objective**: The goal is likely to navigate through the obstacles and enemies while maximizing rewards.\n",
      "\n",
      "4. **Possible Actions**:\n",
      "   - **NOOP**: Doing nothing might not be optimal as it doesn't help in avoiding obstacles or enemies.\n",
      "   - **UP**: Continuing to move UP seems to be working well based on the previous rewards.\n",
      "   - **RIGHT** or **LEFT**: Moving horizontally might help avoid obstacles but could also lead to collisions if not carefully timed.\n",
      "   - **DOWN**: Moving DOWN might not be ideal as it could bring the player closer to other obstacles or enemies.\n",
      "\n",
      "Given the consistent rewards from moving UP and the current position of the player relative to the obstacles, the best action appears to be continuing to move UP.\n",
      "\n",
      "<action>UP</action>\n",
      "Step 114 action: 1\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. **Previous Actions and Rewards**: The last three actions were all \"UP\" and each resulted in a reward of 1.0. This suggests that moving up is currently beneficial.\n",
      "\n",
      "2. **Current Game State**:\n",
      "   - The player character (purple) is at the bottom of the screen.\n",
      "   - There are obstacles and enemies above the player.\n",
      "   - The score has increased from 4 to 6, indicating progress.\n",
      "\n",
      "3. **Objective**: The goal is likely to navigate through the obstacles and enemies while maximizing rewards.\n",
      "\n",
      "4. **Possible Actions**:\n",
      "   - **NOOP**: Doing nothing might not be optimal as it doesn't help in avoiding obstacles or enemies.\n",
      "   - **UP**: Continuing to move up seems to be working well based on the previous rewards.\n",
      "   - **RIGHT** and **LEFT**: Moving horizontally might not be necessary unless there is a specific obstacle that requires avoidance.\n",
      "   - **DOWN**: Moving down would likely lead to collision with obstacles or enemies.\n",
      "\n",
      "Given the analysis, the best action is to continue moving up as it has been successful so far.\n",
      "\n",
      "<action>UP</action>\n",
      "Step 115 action: 1\n",
      "To determine the appropriate action, let's analyze the current state of the game and the previous actions taken:\n",
      "\n",
      "1. **Previous Actions and Rewards**: The last three actions were all \"UP,\" and each resulted in a reward of 1.0. This suggests that moving up is beneficial in the current context.\n",
      "\n",
      "2. **Current Game State**:\n",
      "   - The player character (represented by the white figure) is positioned near the center of the screen.\n",
      "   - There are obstacles and enemies above the player, which might be the reason for the rewards when moving up.\n",
      "   - The score has increased from 5 to 7, indicating progress in the game.\n",
      "\n",
      "3. **Objective**: The goal is likely to navigate through the obstacles and enemies while maximizing rewards.\n",
      "\n",
      "4. **Action Analysis**:\n",
      "   - **NOOP**: Doing nothing might not help in avoiding obstacles or enemies.\n",
      "   - **UP**: Continuing to move up has been successful so far, as indicated by the rewards.\n",
      "   - **RIGHT** and **LEFT**: Moving horizontally might not help in avoiding the immediate obstacles above.\n",
      "   - **DOWN**: Moving down could potentially lead to more obstacles or enemies, reducing the chance of receiving a reward.\n",
      "\n",
      "Given the analysis, the best action to take is to continue moving up, as it has been successful in the past few steps.\n",
      "\n",
      "<action>UP</action>\n",
      "Step 116 action: 1\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. **Previous Actions and Rewards**: The last three actions were all \"UP\" and each resulted in a reward of 1.0. This suggests that moving up is currently beneficial.\n",
      "\n",
      "2. **Current Game State**:\n",
      "   - The player's position is at the bottom of the screen.\n",
      "   - There are obstacles and enemies above the player.\n",
      "   - The player appears to be navigating through a level with platforms and enemies.\n",
      "\n",
      "3. **Objective**: The goal is likely to navigate through the level while avoiding enemies and collecting rewards.\n",
      "\n",
      "4. **Possible Actions**:\n",
      "   - **NOOP**: Doing nothing might not help progress.\n",
      "   - **UP**: Moving up has been successful so far, but we need to check if it's still safe.\n",
      "   - **RIGHT** or **LEFT**: Moving horizontally might help avoid enemies or reach a new area.\n",
      "   - **DOWN**: Moving down might not be useful as there are no platforms below.\n",
      "\n",
      "5. **Decision**:\n",
      "   - Since moving up has been consistently rewarded, it seems like the player is on a path that requires continuous upward movement.\n",
      "   - However, it's important to check if there are any immediate threats or obstacles directly above the player.\n",
      "\n",
      "Given the consistent rewards for moving up and the absence of visible immediate threats directly above, the best action is likely to continue moving up.\n",
      "\n",
      "<action>UP</action>\n",
      "Step 117 action: 1\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. **Previous Actions and Rewards**: The last three actions were all \"UP\" and each resulted in a reward of 1.0. This suggests that moving up is beneficial in the current context.\n",
      "\n",
      "2. **Current Game State**:\n",
      "   - The player's position is at the bottom of the screen.\n",
      "   - There are obstacles and enemies above the player.\n",
      "   - The score has increased from 7 to 9, indicating successful navigation and possibly collecting items or avoiding enemies.\n",
      "\n",
      "3. **Objective**: The goal is likely to navigate through the obstacles and collect items while avoiding enemies. Moving up seems to be a successful strategy so far.\n",
      "\n",
      "4. **Possible Actions**:\n",
      "   - **NOOP**: Doing nothing might not help in progressing further.\n",
      "   - **UP**: Continuing to move up could help in navigating further and potentially collecting more items.\n",
      "   - **RIGHT** or **LEFT**: Moving horizontally might not be as effective if the objective is to navigate upwards.\n",
      "   - **DOWN**: Moving down would likely lead to collision with obstacles or enemies.\n",
      "\n",
      "Given the analysis, the best action to continue the upward progress and maintain the positive reward trend is:\n",
      "\n",
      "<action>UP</action>\n",
      "Step 118 action: 1\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. **Previous Actions and Rewards**:\n",
      "   - Step 117: <action>UP</action> with a reward of 1.0.\n",
      "   - Step 118: <action>UP</action> with a reward of 1.0.\n",
      "   - Step 119: <action>UP</action> with a reward of 0.0.\n",
      "\n",
      "2. **Current State Analysis**:\n",
      "   - The player's position is at the bottom of the screen.\n",
      "   - There are obstacles (yellow dots) above the player.\n",
      "   - The player has been moving up but received no reward in the last step, indicating that further upward movement might not be beneficial.\n",
      "\n",
      "3. **Possible Actions**:\n",
      "   - **NOOP**: Do nothing. This might be useful if the player needs to wait for an obstacle to clear.\n",
      "   - **UP**: Continue moving up. This might not be optimal since the last upward move did not yield a reward.\n",
      "   - **RIGHT**: Move right. This could help avoid obstacles or reach a new area.\n",
      "   - **LEFT**: Move left. Similar to moving right, this could help navigate around obstacles.\n",
      "   - **DOWN**: Move down. This might be useful if there are obstacles directly above the player.\n",
      "\n",
      "4. **Decision**:\n",
      "   - Since moving up did not yield a reward in the last step, it might be better to explore other directions.\n",
      "   - Moving right or left could help the player navigate around obstacles.\n",
      "   - Given the symmetry of the game, moving right seems like a reasonable choice to explore a new area.\n",
      "\n",
      "Therefore, the recommended action is: <action>RIGHT</action>.\n",
      "Step 119 action: 1\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions taken:\n",
      "\n",
      "1. **Current State Analysis**:\n",
      "   - The player is at the top of the screen.\n",
      "   - There are no immediate threats or rewards directly above the player.\n",
      "   - The player has been moving up in the past few steps (Steps 118, 119, and 120).\n",
      "\n",
      "2. **Past Actions and Rewards**:\n",
      "   - Step 118: Moving up resulted in a reward of 1.0.\n",
      "   - Steps 119 and 120: Moving up resulted in no reward (0.0).\n",
      "\n",
      "3. **Reasoning**:\n",
      "   - Since the player is already at the top of the screen and there are no immediate benefits from moving further up, continuing to move up may not be optimal.\n",
      "   - The player should consider exploring other directions to find potential rewards or avoid threats.\n",
      "\n",
      "4. **Action Selection**:\n",
      "   - Given that the player is at the top and moving up is not yielding further rewards, it would be logical to try moving in another direction.\n",
      "   - Moving right or left could help explore new areas of the screen for potential rewards.\n",
      "\n",
      "Based on this reasoning, the best action to take next is to move right.\n",
      "\n",
      "<action>RIGHT</action>\n",
      "Step 120 action: 2\n",
      "To determine the next action, let's analyze the current state of the game:\n",
      "\n",
      "1. **Player Position**: The player is located at the bottom center of the screen.\n",
      "2. **Enemies and Obstacles**: There are several enemies and obstacles in the upper part of the screen. The player needs to navigate through these without colliding.\n",
      "3. **Pathway**: The player has a clear path to the right side of the screen, as there are no immediate obstacles blocking the way.\n",
      "\n",
      "Given this analysis, the best action would be to continue moving to the right to avoid any potential collisions with enemies or obstacles.\n",
      "\n",
      "<action>RIGHT</action>\n",
      "Step 121 action: 2\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. **Current State Analysis**:\n",
      "   - The player is at the bottom of the screen.\n",
      "   - There are obstacles (purple and green objects) in the path.\n",
      "   - The player needs to navigate through these obstacles to reach the top.\n",
      "\n",
      "2. **Previous Actions**:\n",
      "   - Step 120: <action>UP</action> - The player moved up but encountered an obstacle.\n",
      "   - Step 121: <action>RIGHT</action> - The player moved right, possibly to avoid the obstacle.\n",
      "   - Step 122: <action>RIGHT</action> - The player continued moving right, likely still trying to avoid obstacles.\n",
      "\n",
      "3. **Next Action Reasoning**:\n",
      "   - The player has been moving right to avoid obstacles.\n",
      "   - The next logical step would be to continue moving right if there are no immediate obstacles in that direction.\n",
      "   - If moving right is not possible or does not lead to progress, the player might need to consider other directions like up or down.\n",
      "\n",
      "Given the current state and the need to navigate through obstacles, the best action seems to be continuing to move right.\n",
      "\n",
      "<action>RIGHT</action>\n",
      "Step 122 action: 1\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. **Current State Analysis**:\n",
      "   - The player is in a maze-like environment with various obstacles and enemies.\n",
      "   - The player's position is near the center-right of the screen.\n",
      "   - There are multiple enemies (red dots) and obstacles (green and yellow blocks) around the player.\n",
      "\n",
      "2. **Previous Actions**:\n",
      "   - Step 121: <action>RIGHT</action> - The player moved right but did not encounter any reward or significant change.\n",
      "   - Step 122: <action>RIGHT</action> - Another move to the right, still no reward.\n",
      "   - Step 123: <action>UP</action> - The player moved up, again no reward.\n",
      "\n",
      "3. **Reasoning for Next Action**:\n",
      "   - Moving right and up did not yield any rewards, indicating that these directions might be blocked or not leading to a reward.\n",
      "   - The player is currently surrounded by obstacles and enemies, so moving left or down might help avoid them.\n",
      "   - Moving down could potentially lead to an open path or a reward since the lower part of the screen seems less obstructed.\n",
      "\n",
      "Given this analysis, the best action to take next is to move down.\n",
      "\n",
      "<action>DOWN</action>\n",
      "Step 123 action: 2\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. **Current State Analysis**:\n",
      "   - The player is in a position where they are facing multiple enemies.\n",
      "   - The player has moved right and up in the previous steps, indicating an attempt to navigate through the enemies.\n",
      "\n",
      "2. **Objective**:\n",
      "   - The goal is likely to avoid being hit by the enemies and possibly collect items or reach a specific area on the screen.\n",
      "\n",
      "3. **Possible Actions**:\n",
      "   - **NOOP**: Doing nothing might not be effective as the enemies are close.\n",
      "   - **UP**: Moving up could help avoid some enemies but might lead to others.\n",
      "   - **RIGHT**: Continuing to move right could help navigate past the enemies if there is a clear path.\n",
      "   - **LEFT**: Moving left could also help avoid enemies if there is a clear path.\n",
      "   - **DOWN**: Moving down might not be ideal as it could bring the player closer to other enemies.\n",
      "\n",
      "4. **Decision**:\n",
      "   - Given the current position and the need to avoid enemies, moving **RIGHT** seems like a reasonable choice as it continues the previous movement strategy and might help navigate past the enemies.\n",
      "\n",
      "Therefore, the action to take is <action>RIGHT</action>.\n",
      "Step 124 action: 2\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions taken:\n",
      "\n",
      "1. **Current State Analysis**:\n",
      "   - The player is in a maze-like environment with various obstacles and enemies.\n",
      "   - The player's position is at the bottom center of the screen.\n",
      "   - There are enemies (pink and green) moving around the maze.\n",
      "   - The player has previously moved up and then right.\n",
      "\n",
      "2. **Objective**:\n",
      "   - The goal is likely to navigate through the maze while avoiding enemies and possibly collecting items or reaching a specific location.\n",
      "\n",
      "3. **Previous Actions**:\n",
      "   - Step 123: Moved up, reward 0.0\n",
      "   - Step 124: Moved right, reward 0.0\n",
      "   - Step 125: Moved right, reward 0.0\n",
      "\n",
      "4. **Next Action Reasoning**:\n",
      "   - Moving up again might not be optimal as it could lead to collision with the wall or enemies.\n",
      "   - Moving left could potentially help avoid enemies and find a new path.\n",
      "   - Moving down might also be a viable option if there is a clear path below.\n",
      "\n",
      "Given the current position and the need to avoid enemies, moving left seems like a reasonable choice to explore a new path and avoid potential collisions.\n",
      "\n",
      "Therefore, the next action should be: <action>LEFT</action>\n",
      "Step 125 action: 3\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. **Current State**: The player is in a position where they are facing enemies and obstacles.\n",
      "2. **Previous Actions**:\n",
      "   - Step 124: <action>RIGHT</action> with reward 0.0\n",
      "   - Step 125: <action>RIGHT</action> with reward 0.0\n",
      "   - Step 126: <action>LEFT</action> with reward 0.0\n",
      "\n",
      "The player has been moving right and then left, indicating an attempt to navigate through the environment. Given the current position, it seems the player needs to continue navigating to avoid enemies and reach objectives.\n",
      "\n",
      "3. **Possible Actions**:\n",
      "   - **NOOP**: Doing nothing might not be effective as the player needs to move to avoid enemies.\n",
      "   - **UP**: Moving up could help the player avoid some enemies and obstacles.\n",
      "   - **RIGHT**: Continuing right might lead to more enemies or obstacles.\n",
      "   - **LEFT**: Moving left might also lead to more enemies or obstacles.\n",
      "   - **DOWN**: Moving down could help the player avoid some enemies and obstacles.\n",
      "\n",
      "Given the current position and the need to navigate through the environment, moving up seems like a strategic choice to avoid immediate threats and progress.\n",
      "\n",
      "Therefore, the next action should be: <action>UP</action>\n",
      "Step 126 action: 2\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. **Current State Analysis**:\n",
      "   - The player is in a maze-like environment with various obstacles and collectibles.\n",
      "   - The player's position is near the center-right of the screen.\n",
      "   - There are collectibles (dots) both above and below the player.\n",
      "\n",
      "2. **Previous Actions**:\n",
      "   - Step 125: <action>RIGHT</action> resulted in no reward.\n",
      "   - Step 126: <action>LEFT</action> resulted in no reward.\n",
      "   - Step 127: <action>RIGHT</action> resulted in no reward.\n",
      "\n",
      "3. **Reasoning**:\n",
      "   - The player has been moving horizontally without gaining any rewards.\n",
      "   - It might be beneficial to explore vertically to find new collectibles or paths.\n",
      "   - Moving up could potentially lead to more collectibles or open up new areas.\n",
      "\n",
      "Given this analysis, the best action to take next is to move up.\n",
      "\n",
      "<action>UP</action>\n",
      "Step 127 action: 2\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. **Current State Analysis**:\n",
      "   - The player is in a maze-like environment with various obstacles and enemies.\n",
      "   - The player's position is at the bottom center of the screen.\n",
      "   - There are enemies (purple figures) on both sides of the player.\n",
      "\n",
      "2. **Previous Actions**:\n",
      "   - Step 126: The player moved LEFT, but there was no reward.\n",
      "   - Step 127: The player moved RIGHT, but there was no reward.\n",
      "   - Step 128: The player moved RIGHT again, but there was no reward.\n",
      "\n",
      "3. **Reasoning**:\n",
      "   - Moving LEFT or RIGHT has not resulted in any reward, indicating that these directions might be blocked or not leading to a beneficial path.\n",
      "   - The player is currently facing enemies on both sides, so moving horizontally might not be the best option.\n",
      "   - The player needs to find a way to avoid the enemies and possibly move towards an exit or a safer area.\n",
      "\n",
      "4. **Action Selection**:\n",
      "   - Given the current situation, moving UP might help the player navigate through the maze and avoid the enemies.\n",
      "   - Moving UP could potentially lead to a new path or a safer area.\n",
      "\n",
      "Therefore, the next action should be <action>UP</action>.\n",
      "Step 128 action: 1\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. **Step 127**: The player moved RIGHT with a reward of 0.0.\n",
      "2. **Step 128**: The player again moved RIGHT with a reward of 0.0.\n",
      "3. **Step 129**: The player moved UP and received a reward of 1.0.\n",
      "\n",
      "From these steps, it appears that moving UP was beneficial as it resulted in a positive reward. \n",
      "\n",
      "In the current frame:\n",
      "- The player is positioned near the top of the screen.\n",
      "- There are no immediate obstacles directly above the player.\n",
      "- Moving further up might lead to more rewards or progress in the game.\n",
      "\n",
      "Given this analysis, the best action would be to continue moving UP.\n",
      "\n",
      "<action>UP</action>\n",
      "Step 129 action: 1\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions taken:\n",
      "\n",
      "1. **Step 128**: The player moved RIGHT with a reward of 0.0. This suggests that moving right did not result in any immediate benefit.\n",
      "2. **Step 129**: The player moved UP with a reward of 1.0. Moving up resulted in a positive reward, indicating that this was a beneficial move.\n",
      "3. **Step 130**: The player moved UP again with another reward of 1.0. This reinforces that moving up is currently yielding positive results.\n",
      "\n",
      "Given these observations:\n",
      "- Moving UP has been successful in the last two steps, resulting in rewards.\n",
      "- There are no immediate threats or obstacles directly above the player that would prevent further upward movement.\n",
      "\n",
      "Based on this reasoning, the best course of action is to continue moving UP.\n",
      "\n",
      "<action>UP</action>\n",
      "Step 130 action: 1\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions taken:\n",
      "\n",
      "1. **Previous Actions and Rewards**:\n",
      "   - Step 129: <action>UP</action> with a reward of 1.0.\n",
      "   - Step 130: <action>UP</action> with a reward of 1.0.\n",
      "   - Step 131: <action>UP</action> with a reward of 0.0.\n",
      "\n",
      "2. **Current State Analysis**:\n",
      "   - The player character is at the top of the screen.\n",
      "   - There are obstacles (green crosses) and enemies (purple figures) in the path.\n",
      "   - The player has been moving up but received no reward in the last step, indicating that further upward movement might not be beneficial.\n",
      "\n",
      "3. **Possible Actions**:\n",
      "   - **NOOP**: Do nothing. This might be useful if the player needs to wait for something to clear the path.\n",
      "   - **UP**: Continue moving up. However, since the last upward move resulted in no reward, this might not be the best choice.\n",
      "   - **RIGHT**: Move right. This could help avoid obstacles and enemies.\n",
      "   - **LEFT**: Move left. Similar to moving right, this could also help avoid obstacles and enemies.\n",
      "   - **DOWN**: Move down. This could be useful if the player needs to reposition or avoid an obstacle.\n",
      "\n",
      "4. **Decision**:\n",
      "   - Given that moving up did not yield a reward and there are obstacles ahead, it would be prudent to change direction.\n",
      "   - Moving right or left could help navigate around the obstacles and enemies.\n",
      "   - Since the player is already at the top, moving down might not be the best immediate option.\n",
      "\n",
      "Considering these points, the best action would be to move right to avoid the obstacles and continue progressing.\n",
      "\n",
      "<action>RIGHT</action>\n",
      "Step 131 action: 1\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions taken:\n",
      "\n",
      "1. **Current State Analysis**:\n",
      "   - The player is at the bottom of the screen.\n",
      "   - There are obstacles (red circles) above the player.\n",
      "   - The player needs to navigate through these obstacles to reach the top.\n",
      "\n",
      "2. **Previous Actions and Rewards**:\n",
      "   - Step 130: <action>UP</action> with a reward of 1.0. This indicates that moving up was successful.\n",
      "   - Step 131: <action>UP</action> with a reward of 0.0. Moving up did not result in a positive outcome.\n",
      "   - Step 132: <action>UP</action> with a reward of 0.0. Again, moving up did not result in a positive outcome.\n",
      "\n",
      "3. **Reasoning**:\n",
      "   - Since the last two attempts to move up resulted in no reward, it suggests that there might be an obstacle directly above the player.\n",
      "   - The player should consider moving horizontally to avoid the obstacle before attempting to move up again.\n",
      "\n",
      "4. **Action Selection**:\n",
      "   - Given the need to navigate around obstacles, a horizontal movement (LEFT or RIGHT) would be appropriate.\n",
      "   - Since the player is near the center, moving LEFT might help in avoiding the obstacles on the right side.\n",
      "\n",
      "Therefore, the recommended action is: <action>LEFT</action>.\n",
      "Step 132 action: 1\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. **Current State Analysis**:\n",
      "   - The player is at the bottom of the screen.\n",
      "   - There are obstacles (red dots) above the player.\n",
      "   - The player has been moving up in the previous steps.\n",
      "\n",
      "2. **Previous Actions**:\n",
      "   - Step 131: UP\n",
      "   - Step 132: UP\n",
      "   - Step 133: UP\n",
      "\n",
      "3. **Reasoning**:\n",
      "   - The player has been moving up successfully without encountering any obstacles.\n",
      "   - Continuing to move up seems safe as there are no immediate obstacles directly above the player.\n",
      "\n",
      "4. **Action Selection**:\n",
      "   - Since the player is not facing any immediate obstacles and the previous actions were successful, the best course of action is to continue moving up.\n",
      "\n",
      "Therefore, the action to take is <action>UP</action>.\n",
      "Step 133 action: 1\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. The player has been moving UP for the past few steps (Steps 132, 133, and 134).\n",
      "2. The player is currently positioned near the top of the screen.\n",
      "3. There are no immediate threats or obstacles directly above the player that would necessitate continuing to move UP.\n",
      "\n",
      "Given this information, it might be beneficial to explore other directions to potentially find more rewards or avoid any upcoming obstacles. Since the player is already at the top, moving further UP may not be optimal.\n",
      "\n",
      "Let's consider the other actions:\n",
      "- **NOOP**: This would keep the player in place, which might not be the best choice if there are rewards or threats nearby.\n",
      "- **RIGHT** or **LEFT**: These could help the player explore new areas of the screen.\n",
      "- **DOWN**: This could help the player move away from the top and explore lower parts of the screen.\n",
      "\n",
      "Considering these options, moving **DOWN** seems like a reasonable choice to explore new areas and potentially find rewards.\n",
      "\n",
      "<action>DOWN</action>\n",
      "Step 134 action: 4\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. **Current State Analysis**:\n",
      "   - The player is at the bottom of the screen.\n",
      "   - There are obstacles (green blocks) above the player.\n",
      "   - The player needs to navigate through these obstacles to reach the top.\n",
      "\n",
      "2. **Previous Actions**:\n",
      "   - Step 133: <action>UP</action> resulted in a reward of 0.0.\n",
      "   - Step 134: <action>UP</action> resulted in a reward of 0.0.\n",
      "   - Step 135: <action>DOWN</action> resulted in a reward of 0.0.\n",
      "\n",
      "3. **Reasoning**:\n",
      "   - Moving up has not resulted in any negative rewards, indicating it might be a safe move.\n",
      "   - Moving down also did not result in a negative reward, but it doesn't help in reaching the top.\n",
      "   - Since the goal is likely to reach the top, continuing to move up seems logical.\n",
      "\n",
      "Given this analysis, the best action to take next is:\n",
      "\n",
      "<action>UP</action>\n",
      "Step 135 action: 1\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. **Current State Analysis**:\n",
      "   - The player is at the bottom of the screen.\n",
      "   - There are obstacles (green blocks) above the player.\n",
      "   - The player needs to navigate through these obstacles to reach the top.\n",
      "\n",
      "2. **Previous Actions**:\n",
      "   - Step 134: <action>UP</action> resulted in a reward of 0.0.\n",
      "   - Step 135: <action>DOWN</action> resulted in a reward of 0.0.\n",
      "   - Step 136: <action>UP</action> resulted in a reward of 0.0.\n",
      "\n",
      "3. **Reasoning**:\n",
      "   - The player has been moving up and down without gaining any reward, indicating that simply moving vertically might not be effective.\n",
      "   - The player needs to find a path through the obstacles. Given the layout, moving horizontally might help in finding a clear path.\n",
      "\n",
      "4. **Action Selection**:\n",
      "   - Since the player is currently aligned with a potential gap on the right side, moving right could help in navigating through the obstacles.\n",
      "\n",
      "Therefore, the next action should be <action>RIGHT</action>.\n",
      "Step 136 action: 1\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. **Current State Analysis**:\n",
      "   - The player is at the bottom of the screen.\n",
      "   - There are obstacles (green blocks) above the player.\n",
      "   - The player needs to navigate through these obstacles to reach the top.\n",
      "\n",
      "2. **Previous Actions**:\n",
      "   - Step 135: The player moved DOWN, which did not result in a reward.\n",
      "   - Step 136: The player moved UP, which also did not result in a reward.\n",
      "   - Step 137: The player moved UP again, still no reward.\n",
      "\n",
      "3. **Reasoning**:\n",
      "   - Moving DOWN is not beneficial as it takes the player away from the goal.\n",
      "   - Moving UP has been tried twice without success, indicating that there might be an obstacle directly above the player.\n",
      "   - The player should try moving LEFT or RIGHT to find a path around the obstacles.\n",
      "\n",
      "4. **Decision**:\n",
      "   - Given the need to navigate around obstacles, moving LEFT seems like a logical choice to explore a new path.\n",
      "\n",
      "Therefore, the next action should be <action>LEFT</action>.\n",
      "Step 137 action: 3\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. **Current State Analysis**:\n",
      "   - The player is at the bottom of the screen.\n",
      "   - There are obstacles (green blocks) above the player.\n",
      "   - The player needs to navigate through these obstacles to reach the top.\n",
      "\n",
      "2. **Previous Actions**:\n",
      "   - Step 136: <action>UP</action> - The player moved up but did not encounter any reward or penalty.\n",
      "   - Step 137: <action>UP</action> - The player continued moving up without any reward or penalty.\n",
      "   - Step 138: <action>LEFT</action> - The player moved left, still without any reward or penalty.\n",
      "\n",
      "3. **Reasoning**:\n",
      "   - The player has been moving up and then left, indicating an attempt to navigate around obstacles.\n",
      "   - The current position shows that moving left again might help avoid the obstacles directly above.\n",
      "\n",
      "4. **Action Selection**:\n",
      "   - Since the player is already aligned with a gap in the obstacles on the left side, continuing to move left will help in navigating through the obstacles.\n",
      "\n",
      "Therefore, the next action should be <action>LEFT</action>.\n",
      "Step 138 action: 1\n",
      "To determine the next action, let's analyze the current state of the game:\n",
      "\n",
      "1. The player is positioned at the bottom center of the screen.\n",
      "2. There are obstacles and enemies above the player.\n",
      "3. The player needs to navigate through these obstacles and enemies to progress.\n",
      "\n",
      "Given the current position and the layout:\n",
      "- Moving **UP** will likely lead to a collision with an obstacle or enemy.\n",
      "- Moving **LEFT** or **RIGHT** might help avoid immediate obstacles but doesn't seem to provide a clear path forward.\n",
      "- Moving **DOWN** is not possible as the player is already at the bottom.\n",
      "\n",
      "The best option seems to be moving **RIGHT** to explore a potential path that avoids immediate obstacles.\n",
      "\n",
      "<action>RIGHT</action>\n",
      "Step 139 action: 2\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions taken:\n",
      "\n",
      "1. **Current State Analysis**:\n",
      "   - The player character is at the bottom center of the screen.\n",
      "   - There are obstacles (purple and green shapes) in the path above the player.\n",
      "   - The goal appears to be navigating through these obstacles.\n",
      "\n",
      "2. **Previous Actions**:\n",
      "   - Step 138: <action>LEFT</action> - The player moved left.\n",
      "   - Step 139: <action>UP</action> - The player moved up.\n",
      "   - Step 140: <action>RIGHT</action> - The player moved right.\n",
      "\n",
      "3. **Reasoning for Next Action**:\n",
      "   - The player has been moving horizontally and vertically, trying to navigate through the obstacles.\n",
      "   - The current position shows that moving further right might help avoid the obstacles directly above.\n",
      "   - Moving up again might not be optimal as there are obstacles directly above.\n",
      "\n",
      "Given this analysis, the best action would be to continue moving right to avoid the obstacles.\n",
      "\n",
      "<action>RIGHT</action>\n",
      "Step 140 action: 3\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. **Current State Analysis**:\n",
      "   - The player is at the bottom of the screen.\n",
      "   - There are obstacles (purple and green objects) in the middle of the screen.\n",
      "   - The goal appears to be navigating through these obstacles.\n",
      "\n",
      "2. **Previous Actions**:\n",
      "   - Step 139: <action>UP</action> resulted in no reward.\n",
      "   - Step 140: <action>RIGHT</action> resulted in no reward.\n",
      "   - Step 141: <action>LEFT</action> resulted in no reward.\n",
      "\n",
      "3. **Reasoning**:\n",
      "   - Moving up, right, or left did not result in any reward, indicating that these directions might not be optimal at this moment.\n",
      "   - The player is still at the bottom, suggesting that moving down might help in navigating further.\n",
      "\n",
      "4. **Action Selection**:\n",
      "   - Given the current position and the lack of progress with the previous actions, moving down could potentially help in finding a path through the obstacles.\n",
      "\n",
      "Therefore, the next action should be <action>DOWN</action>.\n",
      "Step 141 action: 1\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. **Step 140**: The player moved RIGHT, but there was no reward.\n",
      "2. **Step 141**: The player moved LEFT, again with no reward.\n",
      "3. **Step 142**: The player moved UP and received a reward of 1.0.\n",
      "\n",
      "From this sequence, it appears that moving UP resulted in a positive outcome. Given the current frame, the player is positioned near the top of the screen, which suggests that continuing to move UP might be beneficial.\n",
      "\n",
      "Therefore, the next action should be:\n",
      "<action>UP</action>\n",
      "Step 142 action: 1\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions taken:\n",
      "\n",
      "1. **Previous Actions and Rewards**:\n",
      "   - Step 141: <action>LEFT</action> with a reward of 0.0.\n",
      "   - Step 142: <action>UP</action> with a reward of 1.0.\n",
      "   - Step 143: <action>UP</action> with a reward of 1.0.\n",
      "\n",
      "2. **Current State Analysis**:\n",
      "   - The player character is at the top left corner of the screen.\n",
      "   - There are obstacles and enemies in the path.\n",
      "   - The score has increased from 11 to 13, indicating progress.\n",
      "\n",
      "3. **Possible Actions**:\n",
      "   - **NOOP**: No action, which might not be optimal as it doesn't help in progressing.\n",
      "   - **UP**: Moving up again might lead to more rewards if there are collectibles above.\n",
      "   - **RIGHT**: Moving right could help in navigating around obstacles and enemies.\n",
      "   - **LEFT**: Moving left might not be beneficial as the player is already at the left edge.\n",
      "   - **DOWN**: Moving down could help in avoiding obstacles and enemies below.\n",
      "\n",
      "4. **Decision Making**:\n",
      "   - Since moving up has been rewarding in the past two steps, it might be beneficial to continue moving up if there are more collectibles or paths available.\n",
      "   - However, considering the need to navigate around obstacles and enemies, moving right could also be a good option to explore new areas.\n",
      "\n",
      "Given the analysis, the best action would be to continue exploring upwards as it has been rewarding so far.\n",
      "\n",
      "<action>UP</action>\n",
      "Step 143 action: 3\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. **Step 142**: The player moved UP and received a reward of 1.0. This suggests that moving UP was beneficial.\n",
      "2. **Step 143**: The player again moved UP and received another reward of 1.0. This reinforces that moving UP is currently advantageous.\n",
      "3. **Step 144**: The player moved LEFT but received no reward (0.0). This indicates that moving LEFT did not yield any positive outcome.\n",
      "\n",
      "### Current State Analysis:\n",
      "- The player is positioned near the center of the screen.\n",
      "- There are obstacles and enemies in various directions.\n",
      "- Moving UP has been consistently rewarded in the past two steps.\n",
      "\n",
      "### Reasoning:\n",
      "- Since moving UP has been successful in the last two steps, it is likely that continuing to move UP will still be beneficial unless there is an obstacle or enemy directly above.\n",
      "- There doesn't appear to be an immediate threat or obstacle directly above the player based on the visual information.\n",
      "\n",
      "### Conclusion:\n",
      "Given the consistent rewards from moving UP and the lack of visible threats above, the best action is to continue moving UP.\n",
      "\n",
      "<action>UP</action>\n",
      "Step 144 action: 1\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions taken:\n",
      "\n",
      "1. **Step 143**: The action was `UP`, which resulted in a reward of 1.0. This suggests that moving up was beneficial.\n",
      "2. **Step 144**: The action was `LEFT`, but it did not result in a reward (reward 0.0). This indicates that moving left might not be the best choice at this moment.\n",
      "3. **Step 145**: The action was `UP` again, resulting in another reward of 1.0. This reinforces that moving up is currently advantageous.\n",
      "\n",
      "In the current frame:\n",
      "- The player character appears to be near the top of the screen.\n",
      "- There are obstacles or enemies below the player, which could pose a threat if the player moves down.\n",
      "- Moving right or left might not help avoid these obstacles effectively.\n",
      "\n",
      "Given the pattern of rewards and the current position of the player, the most logical action would be to continue moving up to maintain the positive reward trend and avoid potential threats below.\n",
      "\n",
      "Therefore, the action to choose is: <action>UP</action>.\n",
      "Step 145 action: 1\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. **Step 144**: The player moved LEFT with a reward of 0.0. This suggests that moving left did not result in any immediate benefit or penalty.\n",
      "2. **Step 145**: The player moved UP with a reward of 1.0. This indicates that moving up was beneficial, possibly because it allowed the player to collect an item or avoid an obstacle.\n",
      "3. **Step 146**: The player moved UP again with a reward of 0.0. Moving up again did not yield any additional reward, suggesting that the immediate benefit from moving up has already been realized.\n",
      "\n",
      "Given this information, the player should consider exploring other directions to continue progressing in the game. Since moving up did not provide further rewards, the next logical step would be to try moving in another direction.\n",
      "\n",
      "- **NOOP**: Doing nothing might not help in advancing the game.\n",
      "- **UP**: Already tried and did not yield further rewards.\n",
      "- **RIGHT**: Could potentially lead to new areas or items.\n",
      "- **LEFT**: Already tried and did not yield rewards.\n",
      "- **DOWN**: Could also lead to new areas or items.\n",
      "\n",
      "Considering the need to explore new areas, moving RIGHT or DOWN are viable options. Given the layout of the game, moving RIGHT seems like a reasonable choice as it may allow the player to access new parts of the level.\n",
      "\n",
      "Therefore, the next action should be: <action>RIGHT</action>.\n",
      "Step 146 action: 2\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. **Step 145**: The action was `UP` and it resulted in a reward of 1.0. This suggests that moving up was beneficial.\n",
      "2. **Step 146**: The action was again `UP`, but this time there was no reward (0.0). This indicates that while moving up was initially good, continuing to move up might not be as effective.\n",
      "3. **Step 147**: The action was `RIGHT` with no reward (0.0). Moving right did not yield any immediate benefit.\n",
      "\n",
      "### Current State Analysis:\n",
      "- The player is near the top of the screen, close to the enemies.\n",
      "- There are obstacles and enemies above and to the right.\n",
      "- The player needs to navigate through the environment to avoid enemies and collect rewards.\n",
      "\n",
      "### Reasoning for Next Action:\n",
      "- Since moving `UP` and `RIGHT` did not yield positive results recently, it might be beneficial to explore other directions.\n",
      "- Moving `LEFT` could help the player avoid the enemies and obstacles on the right side.\n",
      "- Moving `DOWN` could also be a viable option to get away from the enemies at the top.\n",
      "\n",
      "Given the need to avoid enemies and find a path forward, the best action seems to be moving `LEFT`.\n",
      "\n",
      "<action>LEFT</action>\n",
      "Step 147 action: 3\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions taken:\n",
      "\n",
      "1. **Current State Analysis**:\n",
      "   - The player character is in the middle of the screen.\n",
      "   - There are obstacles (pink stars) on both sides of the player.\n",
      "   - The player seems to be moving horizontally, as indicated by the recent actions: UP, RIGHT, LEFT.\n",
      "\n",
      "2. **Previous Actions**:\n",
      "   - Step 146: <action>UP</action> - The player moved up.\n",
      "   - Step 147: <action>RIGHT</action> - The player moved right.\n",
      "   - Step 148: <action>LEFT</action> - The player moved left.\n",
      "\n",
      "3. **Objective**:\n",
      "   - The goal appears to be navigating through the obstacles while avoiding them.\n",
      "\n",
      "4. **Reasoning**:\n",
      "   - Moving up or down might help avoid the obstacles.\n",
      "   - Since the player has already moved left and right, it might be beneficial to try a vertical movement.\n",
      "\n",
      "Given this analysis, the best action to take next would be to move up again to potentially clear the path:\n",
      "\n",
      "<action>UP</action>\n",
      "Step 148 action: 1\n",
      "To determine the next action, let's analyze the current state of the game:\n",
      "\n",
      "1. The player is positioned in the middle of the screen.\n",
      "2. There are obstacles and enemies above the player.\n",
      "3. The player needs to navigate through the level while avoiding obstacles and enemies.\n",
      "\n",
      "Given the current position:\n",
      "- Moving **UP** would likely lead to a collision with the obstacles or enemies above.\n",
      "- Moving **RIGHT** or **LEFT** might not be optimal as there are no immediate threats or rewards in those directions.\n",
      "- Moving **DOWN** could help the player avoid the obstacles and enemies above and potentially reach a safer area or collect rewards.\n",
      "\n",
      "Considering these factors, the best action is to move **DOWN**.\n",
      "\n",
      "<action>DOWN</action>\n",
      "Step 149 action: 4\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. **Step 148**: The player moved LEFT, but there was no reward.\n",
      "2. **Step 149**: The player moved UP, but there was no reward.\n",
      "3. **Step 150**: The player moved DOWN, but there was no reward.\n",
      "\n",
      "From the image in Step 150:\n",
      "- The player is positioned near the center of the screen.\n",
      "- There are obstacles (red dots) above and below the player.\n",
      "- The goal appears to be navigating through the obstacles without colliding with them.\n",
      "\n",
      "Given the current position and the need to avoid obstacles:\n",
      "- Moving LEFT or RIGHT might help navigate around the obstacles.\n",
      "- Moving UP or DOWN could lead to a collision with the red dots.\n",
      "\n",
      "Since the player has already tried moving UP and DOWN without success, it would be logical to try moving horizontally.\n",
      "\n",
      "**Action chosen: <action>RIGHT</action>**\n",
      "\n",
      "This action will help the player move away from the obstacles and potentially find a path forward.\n",
      "Step 150 action: 2\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions taken:\n",
      "\n",
      "1. **Current State Analysis**:\n",
      "   - The player is at the bottom right corner of the screen.\n",
      "   - There are obstacles (red dots) and enemies (purple figures) in the path.\n",
      "   - The goal seems to be navigating through the maze while avoiding obstacles and enemies.\n",
      "\n",
      "2. **Previous Actions**:\n",
      "   - Step 149: <action>UP</action> resulted in no reward.\n",
      "   - Step 150: <action>DOWN</action> resulted in no reward.\n",
      "   - Step 151: <action>RIGHT</action> resulted in no reward.\n",
      "\n",
      "3. **Reasoning**:\n",
      "   - Moving up or down does not seem to be beneficial as it leads to no reward and might bring the player closer to obstacles or enemies.\n",
      "   - Moving right has been tried and also resulted in no reward.\n",
      "   - The only direction left to explore is moving left, which might help in avoiding obstacles and enemies and potentially lead to a better position.\n",
      "\n",
      "Based on this reasoning, the next action should be:\n",
      "\n",
      "<action>LEFT</action>\n",
      "Step 151 action: 1\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. **Step 150**: The action was `DOWN`, and the reward was 0.0. This suggests that moving down did not result in any immediate benefit or penalty.\n",
      "2. **Step 151**: The action was `RIGHT`, and the reward was 0.0. Moving right also did not yield any immediate benefit or penalty.\n",
      "3. **Step 152**: The action was `UP`, and the reward was 0.0. Moving up similarly did not result in any immediate benefit or penalty.\n",
      "\n",
      "From the image:\n",
      "- The player character is at the bottom of the screen.\n",
      "- There are obstacles and enemies above the player.\n",
      "- The goal seems to be navigating through the environment while avoiding obstacles and enemies.\n",
      "\n",
      "Given the current position of the player and the layout of the environment:\n",
      "- Moving `UP` again might help the player avoid the obstacles and enemies that are currently above them.\n",
      "- Moving `RIGHT` or `LEFT` might not be beneficial as there are no clear paths in those directions without encountering obstacles.\n",
      "\n",
      "Therefore, the best action to take next is to continue moving `UP`.\n",
      "\n",
      "<action>UP</action>\n",
      "Step 152 action: 1\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. **Current State Analysis**:\n",
      "   - The player is positioned at the bottom center of the screen.\n",
      "   - There are obstacles (purple blocks) in the middle section of the screen.\n",
      "   - The goal appears to be navigating through these obstacles.\n",
      "\n",
      "2. **Previous Actions**:\n",
      "   - Step 151: <action>RIGHT</action> - The player moved right but did not encounter any immediate obstacle.\n",
      "   - Step 152: <action>UP</action> - The player moved up, likely to avoid an obstacle or move towards a path.\n",
      "   - Step 153: <action>UP</action> - The player continued moving up, possibly to navigate further through the obstacles.\n",
      "\n",
      "3. **Next Action Reasoning**:\n",
      "   - The player has been moving up, which suggests that there might be a clear path upwards.\n",
      "   - Continuing to move up could help the player navigate through the obstacles and reach the top of the screen.\n",
      "\n",
      "Given this analysis, the most logical next action is to continue moving up.\n",
      "\n",
      "<action>UP</action>\n",
      "Step 153 action: 2\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. **Current State Analysis**:\n",
      "   - The player character is positioned near the center-right of the screen.\n",
      "   - There are obstacles (purple blocks) in front of the player.\n",
      "   - The player has been moving upwards and to the right in the previous steps.\n",
      "\n",
      "2. **Objective**:\n",
      "   - The goal is likely to navigate through the obstacles and reach a higher level or collect items.\n",
      "\n",
      "3. **Possible Actions**:\n",
      "   - **NOOP**: Do nothing. This might not be effective as it doesn't help in navigating.\n",
      "   - **UP**: Moving up could help if there is a path above the obstacles.\n",
      "   - **RIGHT**: Moving right could help if there is a path to the right of the obstacles.\n",
      "   - **LEFT**: Moving left could help if there is a path to the left of the obstacles.\n",
      "   - **DOWN**: Moving down might not be helpful as it moves away from the objective.\n",
      "\n",
      "4. **Decision Making**:\n",
      "   - From the current position, moving right seems like a viable option as it might help in navigating around the obstacles.\n",
      "   - Moving up might also be an option if there is a clear path above the obstacles.\n",
      "\n",
      "Given the analysis, the best action seems to be moving right to navigate around the obstacles.\n",
      "\n",
      "<action>RIGHT</action>\n",
      "Step 154 action: 2\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions taken:\n",
      "\n",
      "1. **Current State Analysis**:\n",
      "   - The player character is in the lower part of the screen.\n",
      "   - There are obstacles and enemies present in the environment.\n",
      "   - The player seems to be moving towards the right side of the screen.\n",
      "\n",
      "2. **Previous Actions**:\n",
      "   - Step 153: <action>UP</action> with a reward of 0.0\n",
      "   - Step 154: <action>RIGHT</action> with a reward of 0.0\n",
      "   - Step 155: <action>RIGHT</action> with a reward of 0.0\n",
      "\n",
      "3. **Reasoning**:\n",
      "   - The player has been moving right for the past two steps.\n",
      "   - Moving right again might help the player avoid obstacles or reach a goal.\n",
      "   - There doesn't seem to be an immediate threat from above or below that would necessitate changing direction.\n",
      "\n",
      "Given this analysis, the most logical next action is to continue moving right.\n",
      "\n",
      "<action>RIGHT</action>\n",
      "Step 155 action: 1\n",
      "To determine the next action, let's analyze the current state of the game:\n",
      "\n",
      "1. The player character is positioned near the center of the screen.\n",
      "2. There are coins (purple objects) directly above the player character.\n",
      "3. The player has just received a reward of 1.0 for moving up, indicating that moving up is beneficial.\n",
      "\n",
      "Given this information, the logical next step would be to continue moving up to collect more coins.\n",
      "\n",
      "<action>UP</action>\n",
      "Step 156 action: 1\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. **Step 155**: The player moved RIGHT with a reward of 0.0. This suggests that moving right did not result in any immediate benefit or penalty.\n",
      "2. **Step 156**: The player moved UP with a reward of 1.0. This indicates that moving up was beneficial, possibly because it allowed the player to collect an item or avoid an obstacle.\n",
      "3. **Step 157**: The player moved UP again with a reward of 0.0. Moving up again did not provide any additional reward, which might mean that the player has already collected all available items in that direction or is facing an obstacle.\n",
      "\n",
      "Given this information, the player should consider exploring other directions. Since moving up did not yield further rewards, the next logical step would be to try moving in a different direction, such as LEFT or RIGHT, to explore new areas or collect more items.\n",
      "\n",
      "Considering the layout of the game, moving LEFT seems like a reasonable choice as it may allow the player to access new areas or collect additional items.\n",
      "\n",
      "Therefore, the next action should be: <action>LEFT</action>.\n",
      "Step 157 action: 3\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. **Step 156**: The action was `UP` and it resulted in a reward of 1.0. This suggests that moving up was beneficial.\n",
      "2. **Step 157**: The action was again `UP`, but this time there was no reward (0.0). This indicates that while moving up wasn't harmful, it didn't result in any positive outcome either.\n",
      "3. **Step 158**: The action was `LEFT` with no reward (0.0). Moving left also did not yield any positive results.\n",
      "\n",
      "### Current State Analysis:\n",
      "- The player is positioned near the center of the screen.\n",
      "- There are enemies or obstacles above and to the sides.\n",
      "- The player seems to be avoiding these obstacles.\n",
      "\n",
      "### Reasoning for Next Action:\n",
      "- Since moving `UP` previously gave a reward, it might still be a viable option if there are no immediate threats above.\n",
      "- Moving `LEFT` or `RIGHT` could help avoid obstacles, but since the last `LEFT` move didn't yield any reward, it might not be the best choice unless necessary.\n",
      "- Moving `DOWN` could potentially lead to more danger as there seem to be more obstacles below.\n",
      "\n",
      "Given the analysis, the best action would likely be to continue moving `UP` to maintain progress and possibly gain another reward.\n",
      "\n",
      "**Action Chosen:**\n",
      "<action>UP</action>\n",
      "Step 158 action: 1\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. **Current State Analysis**:\n",
      "   - The player is at the bottom of the screen.\n",
      "   - There are obstacles (red dots) above the player.\n",
      "   - The player needs to navigate through these obstacles to reach the top.\n",
      "\n",
      "2. **Previous Actions**:\n",
      "   - Step 157: <action>UP</action> - The player moved up but encountered an obstacle.\n",
      "   - Step 158: <action>LEFT</action> - The player moved left, possibly to avoid an obstacle.\n",
      "   - Step 159: <action>UP</action> - The player moved up again, still encountering obstacles.\n",
      "\n",
      "3. **Reasoning**:\n",
      "   - Moving up directly is not effective as there are obstacles in the way.\n",
      "   - Moving left or right might help in finding a path through the obstacles.\n",
      "   - Given the current position, moving right might provide a better path to navigate through the obstacles.\n",
      "\n",
      "Based on this reasoning, the next action should be:\n",
      "\n",
      "<action>RIGHT</action>\n",
      "Step 159 action: 1\n",
      "To determine the next action, let's analyze the current state of the game:\n",
      "\n",
      "1. The player character is positioned in the middle of the screen.\n",
      "2. There are obstacles and enemies above the player that need to be avoided.\n",
      "3. The player needs to navigate through the level while avoiding these obstacles.\n",
      "\n",
      "Given the current position and the layout of the level:\n",
      "- Moving **UP** would likely lead to collision with the obstacles or enemies above.\n",
      "- Moving **LEFT** or **RIGHT** might not help in progressing further as there are no clear paths in those directions.\n",
      "- Moving **DOWN** could potentially allow the player to avoid the obstacles above and find a path forward.\n",
      "\n",
      "Therefore, the best action to take is:\n",
      "\n",
      "<action>DOWN</action>\n",
      "Step 160 action: 4\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. **Current State Analysis**:\n",
      "   - The player is at the bottom of the screen.\n",
      "   - There are obstacles (red dots) above the player.\n",
      "   - The player needs to navigate through these obstacles to reach the top.\n",
      "\n",
      "2. **Previous Actions**:\n",
      "   - Step 159: <action>UP</action> resulted in no reward.\n",
      "   - Step 160: <action>UP</action> also resulted in no reward.\n",
      "   - Step 161: <action>DOWN</action> resulted in no reward.\n",
      "\n",
      "3. **Reasoning**:\n",
      "   - Moving up has not resulted in a reward, indicating that there might be an obstacle directly above the player.\n",
      "   - Moving down also did not result in a reward, which suggests that moving down further might not be beneficial.\n",
      "   - The player needs to find a way to navigate around the obstacles. Given the layout, moving right or left might help avoid the obstacles.\n",
      "\n",
      "4. **Action Selection**:\n",
      "   - Since the player is currently aligned with the obstacles, moving right or left could help bypass them.\n",
      "   - Let's try moving right first to see if it helps in navigating around the obstacles.\n",
      "\n",
      "Therefore, the next action should be: <action>RIGHT</action>.\n",
      "Step 161 action: 1\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. **Current State Analysis**:\n",
      "   - The player character (X) is at the bottom center of the screen.\n",
      "   - There are obstacles and enemies above the player.\n",
      "   - The player seems to be in a position where moving up or down might be necessary to avoid obstacles.\n",
      "\n",
      "2. **Previous Actions**:\n",
      "   - Step 160: <action>UP</action> with reward 0.0\n",
      "   - Step 161: <action>DOWN</action> with reward 0.0\n",
      "   - Step 162: <action>UP</action> with reward 0.0\n",
      "\n",
      "3. **Reasoning**:\n",
      "   - The player has been alternating between UP and DOWN actions.\n",
      "   - Since the last action was UP, it might be beneficial to continue moving up to avoid any obstacles that might be coming from below.\n",
      "   - Moving up could also help the player progress further in the game by reaching higher platforms.\n",
      "\n",
      "Given this analysis, the next action should be:\n",
      "\n",
      "<action>UP</action>\n",
      "Step 162 action: 1\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. **Current State Analysis**:\n",
      "   - The player is at the bottom of the screen.\n",
      "   - There are obstacles (pink and blue objects) above the player.\n",
      "   - The player needs to navigate through these obstacles to reach the top.\n",
      "\n",
      "2. **Previous Actions**:\n",
      "   - Step 161: The player moved DOWN, which did not result in a reward.\n",
      "   - Step 162: The player moved UP, which also did not result in a reward.\n",
      "   - Step 163: The player moved UP again, still no reward.\n",
      "\n",
      "3. **Reasoning**:\n",
      "   - Moving DOWN is not beneficial as it takes the player away from the goal.\n",
      "   - Moving UP has been tried twice without success, indicating that there might be an obstacle directly above the player.\n",
      "   - The player should try moving LEFT or RIGHT to avoid the obstacles and find a clear path upwards.\n",
      "\n",
      "4. **Decision**:\n",
      "   - Given the obstacles directly above, moving LEFT or RIGHT is necessary to find a clear path.\n",
      "   - Since the player is centered, moving LEFT first can help explore the left side for a clear path.\n",
      "\n",
      "Therefore, the next action should be <action>LEFT</action>.\n",
      "Step 163 action: 3\n",
      "To determine the next action, let's analyze the current state of the game and the position of the player character (the red \"X\") relative to the obstacles and goals.\n",
      "\n",
      "1. **Current Position**: The player character is on the left side of the screen, near the bottom.\n",
      "2. **Obstacles**: There are several obstacles in the form of pink and green blocks scattered across the screen.\n",
      "3. **Goals**: The goal appears to be reaching the top of the screen, as indicated by the score at the top.\n",
      "\n",
      "Given the current position:\n",
      "- Moving **UP** will help the player progress towards the top of the screen.\n",
      "- Moving **LEFT** or **RIGHT** will not directly contribute to reaching the top.\n",
      "- Moving **DOWN** will move the player away from the goal.\n",
      "\n",
      "Since the player needs to reach the top, the best action is to continue moving **UP**.\n",
      "\n",
      "<action>UP</action>\n",
      "Step 164 action: 1\n",
      "To determine the next action, let's analyze the current state of the game and the previous actions:\n",
      "\n",
      "1. **Current State Analysis**:\n",
      "   - The player character is at the bottom center of the screen.\n",
      "   - There are obstacles (pink and green characters) in the middle section of the screen.\n",
      "   - The goal appears to be navigating through these obstacles to reach the top.\n",
      "\n",
      "2. **Previous Actions**:\n",
      "   - Step 163: <action>UP</action> resulted in no reward.\n",
      "   - Step 164: <action>LEFT</action> resulted in no reward.\n",
      "   - Step 165: <action>UP</action> resulted in no reward.\n",
      "\n",
      "3. **Reasoning**:\n",
      "   - The player has been moving up and left but hasn't encountered any positive rewards or reached a new position that suggests progress.\n",
      "   - Given the layout, moving right might help avoid the obstacles and find a path forward.\n",
      "\n",
      "Based on this reasoning, the next action should be:\n",
      "\n",
      "<action>RIGHT</action>\n",
      "Step 165 action: 1\n",
      "GAME ENDED\n",
      "Total reward: 16.0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "max_steps = 1000\n",
    "\n",
    "import enum\n",
    "\n",
    "actions_dict = { \"NOOP\": 0, \"UP\": 1, \"RIGHT\": 2, \"LEFT\": 3, \"DOWN\": 4 }\n",
    "\n",
    "def action_to_index(action: str) -> int:\n",
    "    return actions_dict[action]\n",
    "\n",
    "def index_to_action(index: int) -> str:\n",
    "    return list(actions_dict.keys())[index]\n",
    "\n",
    "state, info = env.reset()\n",
    "actions = []\n",
    "\n",
    "# skip over initial 109 frames (with default frameskip=4) where control is not enabled\n",
    "for step in range(109):\n",
    "    state, reward, terminated, truncated, _ = env.step(0)\n",
    "    save_state(state, step)\n",
    "    actions.append((0, 0))\n",
    "\n",
    "total_reward = 0\n",
    "while step < max_steps:\n",
    "    # with open('frogger_manual.txt', 'r') as f:\n",
    "    #     prompt = f.read()\n",
    "    prompt = \"\\n\\nGiven past frames, reason step by step to choose one of the five actions: NOOP, UP, RIGHT, LEFT, DOWN.\"\n",
    "    prompt += \"Enclose the action you pick in <action></action>\"\n",
    "\n",
    "    action = call_openai(prompt, step, actions)\n",
    "    action = action_to_index(action)\n",
    "\n",
    "    with open('actions.json', 'w+') as f:\n",
    "        f.write(json.dumps(actions))\n",
    "    print(f'Step {step} action: {action} total reward: {total_reward}')\n",
    "\n",
    "    state, reward, terminated, truncated, _ = env.step(action)\n",
    "    actions.append((action, reward))\n",
    "    total_reward += reward\n",
    "    step += 1\n",
    "\n",
    "    save_state(state, step)\n",
    "\n",
    "    if terminated or truncated:\n",
    "        print('GAME ENDED')\n",
    "        break\n",
    "\n",
    "    state, reward, terminated, truncated, _ = env.step(0)\n",
    "    total_reward += reward\n",
    "    if terminated or truncated:\n",
    "        print('GAME ENDED')\n",
    "        break\n",
    "\n",
    "print(f'Total reward: {total_reward}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, image2, from 'states/%01d.png':\n",
      "  Duration: 00:00:06.60, start: 0.000000, bitrate: N/A\n",
      "    Stream #0:0: Video: png, rgb24(pc), 160x210, 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> mpeg4 (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp4, to 'movie.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Video: mpeg4 (mp4v / 0x7634706D), yuv420p, 160x210, q=2-31, 200 kb/s, 25 fps, 12800 tbn, 25 tbc\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 mpeg4\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n",
      "frame=  165 fps=0.0 q=7.3 Lsize=     276kB time=00:00:06.56 bitrate= 345.2kbits/s speed=89.3x    \n",
      "video:275kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.558762%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"ffmpeg -i states/%01d.png -vcodec mpeg4 -y movie.mp4\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
